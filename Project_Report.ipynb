{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eU_JHFSVmpc7",
        "outputId": "5e4cc83a-cdb9-417b-cb82-ab8bb47e53d5"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install mediapipe opencv-python numpy matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "t6MQvHoNje5x",
        "outputId": "d3e16ec9-6ad8-434c-b161-1cda4930d0bb"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from enum import Enum\n",
        "from collections import Counter\n",
        "\n",
        "# --- 1. CONFIGURATION & ENUMS ---\n",
        "class HandShape(Enum):\n",
        "    ROCK = 0\n",
        "    PAPER = 1\n",
        "    SCISSORS = 2\n",
        "    UNKNOWN = -1\n",
        "\n",
        "# --- 2. ADAPTIVE AI BRAIN ---\n",
        "class MarkovPredictor:\n",
        "    def __init__(self):\n",
        "        self.matrix = {} \n",
        "        self.last_move = None\n",
        "        self.total_moves = 0 \n",
        "        \n",
        "    def train(self, move_sequence):\n",
        "        for move in move_sequence:\n",
        "            self.update(move)\n",
        "\n",
        "    def update(self, current_move):\n",
        "        self.total_moves += 1\n",
        "        if self.last_move is not None:\n",
        "            transition = (self.last_move, current_move)\n",
        "            self.matrix[transition] = self.matrix.get(transition, 0) + 1\n",
        "        self.last_move = current_move\n",
        "        \n",
        "    def get_prediction(self):\n",
        "        if self.total_moves < 3 or self.last_move is None:\n",
        "            return None, \"WAITING FOR DATA\"\n",
        "        options = [HandShape.ROCK, HandShape.PAPER, HandShape.SCISSORS]\n",
        "        best_hand, highest = None, -1\n",
        "        for opt in options:\n",
        "            count = self.matrix.get((self.last_move, opt), 0)\n",
        "            if count > highest: highest, best_hand = count, opt\n",
        "        return (best_hand, f\"PREDICT: {best_hand.name}\") if highest > 0 else (None, \"UNCERTAIN\")\n",
        "\n",
        "# --- 3. GAME STRATEGY ---\n",
        "class GameStrategy:\n",
        "    def __init__(self):\n",
        "        self.rules = {\n",
        "            (HandShape.ROCK, HandShape.SCISSORS): 1, (HandShape.ROCK, HandShape.PAPER): -1, (HandShape.ROCK, HandShape.ROCK): 0,\n",
        "            (HandShape.PAPER, HandShape.ROCK): 1, (HandShape.PAPER, HandShape.SCISSORS): -1, (HandShape.PAPER, HandShape.PAPER): 0,\n",
        "            (HandShape.SCISSORS, HandShape.PAPER): 1, (HandShape.SCISSORS, HandShape.ROCK): -1, (HandShape.SCISSORS, HandShape.SCISSORS): 0\n",
        "        }\n",
        "    def get_payoff(self, my, opp): return self.rules.get((my, opp), 0)\n",
        "\n",
        "    def solve_hybrid(self, my_hands, opp_hands, prediction=None):\n",
        "        if prediction is not None and prediction in opp_hands:\n",
        "            score0 = self.get_payoff(my_hands[0], prediction)\n",
        "            score1 = self.get_payoff(my_hands[1], prediction)\n",
        "            if score0 > score1: return my_hands[0], f\"KILLER: {my_hands[0].name}\"\n",
        "            elif score1 > score0: return my_hands[1], f\"KILLER: {my_hands[1].name}\"\n",
        "\n",
        "        score0 = self.get_payoff(my_hands[0], opp_hands[0]) + self.get_payoff(my_hands[0], opp_hands[1])\n",
        "        score1 = self.get_payoff(my_hands[1], opp_hands[0]) + self.get_payoff(my_hands[1], opp_hands[1])\n",
        "        rec = my_hands[0] if score0 >= score1 else my_hands[1]\n",
        "        return rec, f\"NASH: {rec.name}\"\n",
        "\n",
        "# --- 4. COMPUTER VISION (Fixed Logic) ---\n",
        "class HandDetector:\n",
        "    def __init__(self):\n",
        "        self.mp_hands = mp.solutions.hands\n",
        "        self.hands = self.mp_hands.Hands(static_image_mode=True, max_num_hands=4, min_detection_confidence=0.1, model_complexity=1)\n",
        "        self.mp_draw = mp.solutions.drawing_utils\n",
        "\n",
        "    def get_dist(self, p1, p2): return np.hypot(p1.x - p2.x, p1.y - p2.y)\n",
        "\n",
        "    def classify_gesture(self, hand_landmarks):\n",
        "        thumb = self.get_dist(hand_landmarks.landmark[0], hand_landmarks.landmark[4]) > self.get_dist(hand_landmarks.landmark[0], hand_landmarks.landmark[2])\n",
        "        index = self.get_dist(hand_landmarks.landmark[0], hand_landmarks.landmark[8]) > self.get_dist(hand_landmarks.landmark[0], hand_landmarks.landmark[6])\n",
        "        middle = self.get_dist(hand_landmarks.landmark[0], hand_landmarks.landmark[12]) > self.get_dist(hand_landmarks.landmark[0], hand_landmarks.landmark[10])\n",
        "        ring = self.get_dist(hand_landmarks.landmark[0], hand_landmarks.landmark[16]) > self.get_dist(hand_landmarks.landmark[0], hand_landmarks.landmark[14])\n",
        "        pinky = self.get_dist(hand_landmarks.landmark[0], hand_landmarks.landmark[20]) > self.get_dist(hand_landmarks.landmark[0], hand_landmarks.landmark[18])\n",
        "        \n",
        "        total = sum([thumb, index, middle, ring, pinky])\n",
        "        if total <= 1: return HandShape.ROCK\n",
        "        if index and middle and not ring and not pinky: return HandShape.SCISSORS\n",
        "        if total >= 4: return HandShape.PAPER\n",
        "        if total == 3 and index and middle: return HandShape.SCISSORS\n",
        "        return HandShape.UNKNOWN\n",
        "\n",
        "    def process_static(self, image_path):\n",
        "        img = cv2.imread(image_path)\n",
        "        if img is None: return None, []\n",
        "        \n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        results = self.hands.process(img_rgb)\n",
        "        detected = [] \n",
        "        \n",
        "        if results.multi_hand_landmarks:\n",
        "            print(f\"\\n--- Processing {image_path} ---\")\n",
        "            for i, hand_lms in enumerate(results.multi_hand_landmarks):\n",
        "                # --- FIX: USE AVERAGE Y INSTEAD OF WRIST ---\n",
        "                # This calculates the center of the hand, not just the wrist\n",
        "                y_values = [lm.y for lm in hand_lms.landmark]\n",
        "                avg_y = np.mean(y_values)\n",
        "                \n",
        "                shape = self.classify_gesture(hand_lms)\n",
        "                detected.append((shape, avg_y))\n",
        "                \n",
        "                # Determine Color based on Average Y\n",
        "                if avg_y < 0.5:\n",
        "                     print(f\"Hand {i}: Y={avg_y:.2f} (Top) -> Red (Opponent)\")\n",
        "                     l_color, c_color = (255, 0, 0), (255, 0, 0)\n",
        "                else:\n",
        "                     print(f\"Hand {i}: Y={avg_y:.2f} (Bottom) -> Green (You)\")\n",
        "                     l_color, c_color = (0, 255, 0), (0, 255, 0)\n",
        "\n",
        "                self.mp_draw.draw_landmarks(\n",
        "                    img_rgb, hand_lms, self.mp_hands.HAND_CONNECTIONS,\n",
        "                    self.mp_draw.DrawingSpec(color=l_color, thickness=5, circle_radius=5),\n",
        "                    self.mp_draw.DrawingSpec(color=c_color, thickness=3, circle_radius=2)\n",
        "                )\n",
        "        return img_rgb, detected\n",
        "\n",
        "# --- 5. EXECUTION ---\n",
        "def analyze_scenario(image_path, simulated_history=None):\n",
        "    detector = HandDetector()\n",
        "    strategy = GameStrategy()\n",
        "    predictor = MarkovPredictor()\n",
        "    \n",
        "    if simulated_history: predictor.train(simulated_history)\n",
        "\n",
        "    img_rgb, raw_data = detector.process_static(image_path)\n",
        "    if img_rgb is None: print(f\"Error loading {image_path}\"); return\n",
        "\n",
        "    # Sort based on Average Y\n",
        "    all_bottom = [d[0] for d in raw_data if d[1] > 0.5] \n",
        "    all_top = [d[0] for d in raw_data if d[1] <= 0.5]\n",
        "    \n",
        "    print(f\" > Player Has: {[h.name for h in all_bottom]}\")\n",
        "    print(f\" > Opponent Has: {[h.name for h in all_top]}\")\n",
        "\n",
        "    if len(all_bottom) >= 2 and len(all_top) >= 2:\n",
        "        pred_hand, pred_msg = predictor.get_prediction()\n",
        "        rec_hand, advice = strategy.solve_hybrid(all_bottom[:2], all_top[:2], pred_hand)\n",
        "        \n",
        "        h, w, _ = img_rgb.shape\n",
        "        cv2.rectangle(img_rgb, (0, h-90), (w, h), (0,0,0), -1)\n",
        "        cv2.putText(img_rgb, f\"{advice}\", (30, h-30), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 255), 3)\n",
        "    \n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.imshow(img_rgb)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# --- RUN TESTS ---\n",
        "# Replace with your actual filenames\n",
        "image_files = [\"test1.jpg\", \"test2.jpg\"]\n",
        "for img in image_files:\n",
        "    analyze_scenario(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "import time\n",
        "\n",
        "def capture_training_data():\n",
        "    # --- 1. CLEANUP PHASE ---\n",
        "    # Find all files starting with \"test\" and ending in \".jpg\"\n",
        "    old_files = glob.glob(\"test*.jpg\")\n",
        "    for f in old_files:\n",
        "        try:\n",
        "            os.remove(f)\n",
        "            print(f\"Deleted old file: {f}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Could not delete {f}: {e}\")\n",
        "            \n",
        "    print(\"--- OLD DATA CLEARED ---\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    # --- 2. SETUP CAMERA ---\n",
        "    cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
        "    # Force 4:3 aspect ratio\n",
        "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
        "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
        "    \n",
        "    if not cap.isOpened():\n",
        "        print(\"Error: Could not open webcam.\")\n",
        "        return\n",
        "\n",
        "    print(\"--- IMAGE COLLECTION TOOL ---\")\n",
        "    print(\"Instructions:\")\n",
        "    print(\"1. Pose your hands (Top = Opponent, Bottom = You)\")\n",
        "    print(\"2. Press 's' to save the current frame.\")\n",
        "    print(\"3. Press 'q' to quit early.\")\n",
        "    print(\"-\" * 30)\n",
        "    \n",
        "    current_image = 1\n",
        "    max_images = 5\n",
        "    \n",
        "    while current_image <= max_images:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret: break\n",
        "        \n",
        "        # Create UI copy\n",
        "        ui = frame.copy()\n",
        "        h, w, _ = frame.shape\n",
        "        \n",
        "        # Draw Guides\n",
        "        cv2.line(ui, (0, h//2), (w, h//2), (0, 255, 255), 2)\n",
        "        cv2.putText(ui, \"OPPONENT (Top)\", (20, h//2 - 20), \n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
        "        cv2.putText(ui, \"PLAYER (Bottom)\", (20, h//2 + 40), \n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "        \n",
        "        # Status Text\n",
        "        cv2.putText(ui, f\"Capture: {current_image}/5\", (20, 50), \n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "        cv2.putText(ui, \"Press 's' to Save\", (20, 90), \n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)\n",
        "\n",
        "        cv2.imshow(\"Data Collector\", ui)\n",
        "        \n",
        "        key = cv2.waitKey(1)\n",
        "        if key & 0xFF == ord('q'):\n",
        "            break\n",
        "        elif key & 0xFF == ord('s'):\n",
        "            # Save Clean Frame\n",
        "            filename = f\"test{current_image}.jpg\"\n",
        "            cv2.imwrite(filename, frame)\n",
        "            print(f\"[Saved] {filename}\")\n",
        "            \n",
        "            # Flash Effect\n",
        "            cv2.rectangle(ui, (0,0), (w,h), (255,255,255), -1)\n",
        "            cv2.imshow(\"Data Collector\", ui)\n",
        "            cv2.waitKey(150)\n",
        "            \n",
        "            current_image += 1\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    print(\"Collection Complete! 5 new images saved.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    capture_training_data()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNONvJF4Co09v22Vvkt7A9d",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
