{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dbfc0a3",
   "metadata": {},
   "source": [
    "# AISE 3350A Project: RPS-Neural-Link\n",
    "### Cyber-Physical Game Theory System\n",
    "**Group Number:** 4\n",
    "**Group Members:** Michael Trbovic (251358199), Murede Oluwamurede Adetiba (251372276), Tyler Lafond (251359907), William Huang (251371199)\n",
    "**Date:** December 5, 2025\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "### 1.1 Motivation & Background\n",
    "Rock-Paper-Scissors-Minus-One (RPS-1) is a strategic variation of the classic intransitive hand game. Unlike standard RPS, where players throw a single hand, RPS-1 involves a two-stage decision process: players present two hands, then strategically withdraw one. This introduces a complex layer of \"hand selection\" where optimal play requires analyzing the opponent's available options in real-time.\n",
    "\n",
    "In the context of **Cyber-Physical Systems (CPS)**, this project aims to build an Augmented Reality (AR) agent that bridges the physical world (human gestures) and the cyber world (game theory algorithms). Real-time analysis is critical; a delay of even a few milliseconds can render a strategic suggestion obsolete.\n",
    "\n",
    "### 1.2 Objectives\n",
    "The primary goal of the **RPS-Neural-Link** is to create a decision-support system that:\n",
    "1.  **Perceives:** Uses Computer Vision to identify and classify hand gestures from a live video feed or static images.\n",
    "2.  **Analyzes:** Applying Game Theory (Nash Equilibrium) and Adaptive AI (Markov Chains) to determine the optimal move.\n",
    "3.  **Augments:** Projects the calculated move back to the user via a Heads-Up Display (HUD).\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Methods\n",
    "\n",
    "### 2.1 Computer Vision Approach\n",
    "We utilized **Google MediaPipe Hands** rather than object detection models like YOLO.\n",
    "* **Rationale:** RPS requires recognizing the *geometric configuration* of fingers (open vs. closed), not just the presence of a hand. MediaPipe provides 21 3D skeletal landmarks per hand, allowing for high-frequency, low-latency classification without the need for a massive labeled dataset.\n",
    "* **Classification Logic:** We calculate Euclidean distances between specific landmarks (e.g., wrist-to-fingertip vs. wrist-to-knuckle) to determine if fingers are extended.\n",
    "    * **Rock:** 0-1 fingers extended.\n",
    "    * **Scissors:** Index & Middle fingers extended.\n",
    "    * **Paper:** 4-5 fingers extended.\n",
    "\n",
    "### 2.2 Strategic Engine (The \"Cyber\" Component)\n",
    "Our system employs a hybrid decision engine:\n",
    "\n",
    "1.  **The Markov Predictor (Offensive):**\n",
    "    We treat the game as a sequence of events. A first-order Markov Chain records the transition probabilities of the opponent's moves (e.g., $P(Paper | Rock)$). If the opponent exhibits a predictable pattern (probability $> 33\\%$ above random chance), the system predicts their next move and counters it.\n",
    "\n",
    "2.  **Nash Equilibrium (Defensive):**\n",
    "    When the opponent's behavior is random or data is insufficient, the system reverts to the Minimax principle. We calculate the payoff matrix for the current 4-hand configuration (User's 2 hands vs. Opponent's 2 hands) and determine the \"Minus One\" decision that statistically minimizes the maximum possible loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fe4c92",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from enum import Enum\n",
    "from collections import Counter\n",
    "\n",
    "# --- 1. CONFIGURATION & ENUMS ---\n",
    "class HandShape(Enum):\n",
    "    ROCK = 0\n",
    "    PAPER = 1\n",
    "    SCISSORS = 2\n",
    "    UNKNOWN = -1\n",
    "\n",
    "# --- 2. ADAPTIVE AI BRAIN ---\n",
    "class MarkovPredictor:\n",
    "    \"\"\"\n",
    "    Learns opponent patterns over time using a transition matrix.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.matrix = {} \n",
    "        self.last_move = None\n",
    "        self.total_moves = 0 \n",
    "        \n",
    "    def update(self, current_move):\n",
    "        self.total_moves += 1\n",
    "        if self.last_move is not None:\n",
    "            transition = (self.last_move, current_move)\n",
    "            self.matrix[transition] = self.matrix.get(transition, 0) + 1\n",
    "        self.last_move = current_move\n",
    "        \n",
    "    def get_prediction(self):\n",
    "        # Need at least 3 moves to establish a basic pattern\n",
    "        if self.total_moves < 3 or self.last_move is None:\n",
    "            return None, \"WAITING FOR DATA\"\n",
    "            \n",
    "        options = [HandShape.ROCK, HandShape.PAPER, HandShape.SCISSORS]\n",
    "        best_hand, highest_count = None, -1\n",
    "        \n",
    "        # Check which move most frequently follows the last move\n",
    "        for opt in options:\n",
    "            count = self.matrix.get((self.last_move, opt), 0)\n",
    "            if count > highest_count:\n",
    "                highest_count = count\n",
    "                best_hand = opt\n",
    "                \n",
    "        return (best_hand, f\"PREDICT: {best_hand.name}\") if highest_count > 0 else (None, \"UNCERTAIN\")\n",
    "\n",
    "# --- 3. GAME STRATEGY ---\n",
    "class GameStrategy:\n",
    "    \"\"\"\n",
    "    Calculates Optimal Move using Nash Equilibrium or Counter-Play.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # Payoff Matrix: 1 = Win, -1 = Loss, 0 = Tie\n",
    "        self.rules = {\n",
    "            (HandShape.ROCK, HandShape.SCISSORS): 1, (HandShape.ROCK, HandShape.PAPER): -1, (HandShape.ROCK, HandShape.ROCK): 0,\n",
    "            (HandShape.PAPER, HandShape.ROCK): 1, (HandShape.PAPER, HandShape.SCISSORS): -1, (HandShape.PAPER, HandShape.PAPER): 0,\n",
    "            (HandShape.SCISSORS, HandShape.PAPER): 1, (HandShape.SCISSORS, HandShape.ROCK): -1, (HandShape.SCISSORS, HandShape.SCISSORS): 0\n",
    "        }\n",
    "\n",
    "    def get_payoff(self, my, opp):\n",
    "        return self.rules.get((my, opp), 0)\n",
    "\n",
    "    def solve_hybrid(self, my_hands, opp_hands, prediction=None):\n",
    "        # 1. Offensive Mode: If we predict a move, counter it hard.\n",
    "        if prediction is not None and prediction in opp_hands:\n",
    "            score0 = self.get_payoff(my_hands[0], prediction)\n",
    "            score1 = self.get_payoff(my_hands[1], prediction)\n",
    "            if score0 > score1: return my_hands[0], f\"KILLER: {my_hands[0].name}\"\n",
    "            elif score1 > score0: return my_hands[1], f\"KILLER: {my_hands[1].name}\"\n",
    "\n",
    "        # 2. Defensive Mode: Nash Equilibrium\n",
    "        # Calculate expected value of keeping Hand 0 vs Hand 1 against BOTH opponent options\n",
    "        score0 = self.get_payoff(my_hands[0], opp_hands[0]) + self.get_payoff(my_hands[0], opp_hands[1])\n",
    "        score1 = self.get_payoff(my_hands[1], opp_hands[0]) + self.get_payoff(my_hands[1], opp_hands[1])\n",
    "        \n",
    "        # Select the hand with the highest cumulative payoff/safety\n",
    "        rec_hand = my_hands[0] if score0 >= score1 else my_hands[1]\n",
    "        return rec_hand, f\"NASH: {rec_hand.name}\"\n",
    "\n",
    "# --- 4. COMPUTER VISION ---\n",
    "class HandDetector:\n",
    "    def __init__(self):\n",
    "        self.mp_hands = mp.solutions.hands\n",
    "        self.hands = self.mp_hands.Hands(\n",
    "            static_image_mode=True, \n",
    "            max_num_hands=4, \n",
    "            min_detection_confidence=0.5, \n",
    "            model_complexity=1\n",
    "        )\n",
    "        self.mp_draw = mp.solutions.drawing_utils\n",
    "\n",
    "    def get_dist(self, p1, p2):\n",
    "        return math.hypot(p1.x - p2.x, p1.y - p2.y)\n",
    "\n",
    "    def classify_gesture(self, hand_landmarks):\n",
    "        \"\"\"\n",
    "        Geometric classification based on finger extension.\n",
    "        \"\"\"\n",
    "        # Compare tip to PIP joint distance vs wrist distance\n",
    "        tips = [4, 8, 12, 16, 20]\n",
    "        pips = [2, 6, 10, 14, 18]\n",
    "        fingers_open = []\n",
    "        \n",
    "        # Thumb logic (different plane)\n",
    "        fingers_open.append(\n",
    "            self.get_dist(hand_landmarks.landmark[4], hand_landmarks.landmark[17]) > \n",
    "            self.get_dist(hand_landmarks.landmark[3], hand_landmarks.landmark[17])\n",
    "        )\n",
    "\n",
    "        # Other 4 fingers\n",
    "        for i in range(1, 5):\n",
    "            fingers_open.append(\n",
    "                hand_landmarks.landmark[tips[i]].y < hand_landmarks.landmark[pips[i]].y\n",
    "                if hand_landmarks.landmark[0].y > 0.5 else # Flip logic if hand is upside down? \n",
    "                # MediaPipe is normalized, so we stick to geometric distance relative to wrist\n",
    "                self.get_dist(hand_landmarks.landmark[0], hand_landmarks.landmark[tips[i]]) >\n",
    "                self.get_dist(hand_landmarks.landmark[0], hand_landmarks.landmark[pips[i]])\n",
    "            )\n",
    "            \n",
    "        total_open = sum(fingers_open)\n",
    "        \n",
    "        # Classification Rules\n",
    "        if total_open <= 1: return HandShape.ROCK\n",
    "        if fingers_open[1] and fingers_open[2] and not fingers_open[3] and not fingers_open[4]: return HandShape.SCISSORS\n",
    "        if total_open >= 4: return HandShape.PAPER\n",
    "        return HandShape.UNKNOWN\n",
    "\n",
    "    def process_static(self, image_path):\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None: return None, []\n",
    "        \n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        results = self.hands.process(img_rgb)\n",
    "        detected = [] \n",
    "        \n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_lms in results.multi_hand_landmarks:\n",
    "                # Use Average Y to separate players (Top vs Bottom)\n",
    "                y_values = [lm.y for lm in hand_lms.landmark]\n",
    "                avg_y = sum(y_values) / len(y_values)\n",
    "                \n",
    "                shape = self.classify_gesture(hand_lms)\n",
    "                detected.append((shape, avg_y))\n",
    "                \n",
    "                # Visualization\n",
    "                color = (0, 255, 0) if avg_y > 0.5 else (255, 0, 0)\n",
    "                self.mp_draw.draw_landmarks(img_rgb, hand_lms, self.mp_hands.HAND_CONNECTIONS,\n",
    "                                            self.mp_draw.DrawingSpec(color=color, thickness=2, circle_radius=2))\n",
    "                                            \n",
    "        return img_rgb, detected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b9a5f3",
   "metadata": {},
   "source": [
    "## 3. Results & Verification\n",
    "\n",
    "### 3.1 Instructor Verification Block\n",
    "The following code block is designed for reproducibility. It initializes the `HandDetector` and `GameStrategy` classes defined above and iterates through the 5 sample images provided in the submission folder (`test1.jpg` through `test5.jpg`).\n",
    "\n",
    "**How it works:**\n",
    "1.  Loads the image.\n",
    "2.  Detects all hands using MediaPipe.\n",
    "3.  Sorts hands by Y-coordinate (Top = Opponent, Bottom = Player).\n",
    "4.  Calculates the optimal move based on the identified hands.\n",
    "5.  Displays the annotated image with the AI's decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73e76f6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def test_static_image(image_path):\n",
    "    detector = HandDetector()\n",
    "    strategy = GameStrategy()\n",
    "    \n",
    "    print(f\"\\n--- Analyzing {image_path} ---\")\n",
    "    img_rgb, raw_data = detector.process_static(image_path)\n",
    "    \n",
    "    if img_rgb is None:\n",
    "        print(f\"File not found: {image_path}\")\n",
    "        return\n",
    "\n",
    "    # Sort hands: Top (Opponent) vs Bottom (Player)\n",
    "    # MediaPipe Y coordinates: 0.0 is Top, 1.0 is Bottom\n",
    "    all_bottom = [d[0] for d in raw_data if d[1] > 0.5] \n",
    "    all_top = [d[0] for d in raw_data if d[1] <= 0.5]\n",
    "    \n",
    "    print(f\" > Player Hands (Bottom): {[h.name for h in all_bottom]}\")\n",
    "    print(f\" > Opponent Hands (Top):  {[h.name for h in all_top]}\")\n",
    "\n",
    "    if len(all_bottom) >= 1 and len(all_top) >= 1:\n",
    "        # We need at least 1 hand per player to calculate a winner, \n",
    "        # ideally 2 for the full RPS-1 strategy.\n",
    "        # This takes the first 2 hands found for each player.\n",
    "        my_hand_selection = all_bottom[:2]\n",
    "        opp_hand_selection = all_top[:2]\n",
    "        \n",
    "        # If only 1 hand is visible, duplicate it (assume forced move)\n",
    "        if len(my_hand_selection) == 1: my_hand_selection.append(my_hand_selection[0])\n",
    "        if len(opp_hand_selection) == 1: opp_hand_selection.append(opp_hand_selection[0])\n",
    "            \n",
    "        rec_hand, logic = strategy.solve_hybrid(my_hand_selection, opp_hand_selection)\n",
    "        \n",
    "        print(f\" > Strategy Engine: {logic}\")\n",
    "        \n",
    "        # Annotation\n",
    "        h, w, _ = img_rgb.shape\n",
    "        cv2.rectangle(img_rgb, (0, h-60), (w, h), (0,0,0), -1)\n",
    "        cv2.putText(img_rgb, f\"AI: {logic}\", (20, h-20), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    else:\n",
    "        print(\" > Status: Insufficient hands detected for gameplay analysis.\")\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# --- EXECUTION LOOP ---\n",
    "# Ensure test1.jpg, test2.jpg... are in the same folder\n",
    "sample_images = ['test1.jpg', 'test2.jpg', 'test3.jpg', 'test4.jpg', 'test5.jpg']\n",
    "\n",
    "for img_file in sample_images:\n",
    "    test_static_image(img_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84dec12",
   "metadata": {},
   "source": [
    "## 4. Discussion\n",
    "\n",
    "### 4.1 Design Decisions\n",
    "* **MediaPipe vs. YOLO:** We initially considered YOLO for object detection. However, RPS relies on the *state* of the fingers (open/closed) rather than just the object class. Training a YOLO model to distinguish between \"Rock\" and \"Paper\" requires a massive, varied dataset. MediaPipe's skeletal landmarking provided a geometric solution that was robust, lightweight, and required no training data.\n",
    "* **The \"Hybrid\" Notebook:** To ensure reproducibility for grading (as requested), we extracted the core logic classes from our Flask web application (`app.py`) and embedded them directly into this notebook. This allows the instructor to verify the game logic without the complexity of setting up a local web server environment.\n",
    "\n",
    "### 4.2 Challenges & Mitigation\n",
    "* **Lighting & Occlusion:** Computer vision struggles in poor lighting. To mitigate this, we implemented a confidence threshold in `HandDetector` and visual feedback (Red/Green skeletons) so the user knows immediately if tracking is lost.\n",
    "* **Game State Synchronization:** In the real-time app, syncing the AI's calculation with the exact moment players reveal their hands was difficult. We solved this by implementing a `GameState` state machine (IDLE -> COUNTDOWN -> SHOOT) to lock in predictions only at the critical moment.\n",
    "\n",
    "## 5. Conclusion\n",
    "The RPS-Neural-Link project successfully demonstrates a Cyber-Physical System where physical input (gestures) drives cyber analysis (Game Theory), resulting in physical augmentation (AR feedback). The system correctly identifies hand states and applies Nash Equilibrium to provide optimal advice, satisfying the core learning objectives of the course.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. References\n",
    "1.  **MediaPipe:** Lugaresi, C., et al. \"MediaPipe: A Framework for Building Perception Pipelines.\" *arXiv preprint arXiv:1906.08172* (2019).\n",
    "2.  **Flask:** Grinberg, M. \"Flask Web Development: Developing Web Applications with Python.\" *O'Reilly Media, Inc.* (2018).\n",
    "3.  **Nash Equilibrium:** Nash, J. \"Non-cooperative games.\" *Annals of mathematics* (1951): 286-295.\n",
    "\n",
    "---\n",
    "\n",
    "### Appendix: Web Application\n",
    "In addition to this notebook, the submitted zip file contains a full **Flask Web Application** (`app.py`, `templates/`, `static/`). This app provides a fully immersive AR experience with a cyberpunk HUD, live webcam feed, and real-time tournament tracking. A video demonstration of this app is included in the submission."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
